name: Build

on:
  push:
    branches:
      - main

permissions:
  contents: write

jobs:
  windows-zig:
    runs-on: windows-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
        with:
          repository: ggerganov/llama.cpp

      - name: Install Zig (latest)
        uses: goto-bus-stop/setup-zig@v2

      - name: Compile with Zig
        run: |
          zig build -Doptimize=ReleaseFast -Dtarget=x86_64-windows-msvc -Dcpu=x86_64+avx2+fma
          ls zig-out/

  # macos:
  #   runs-on: macos-latest

  #   strategy:
  #     matrix:
  #       include:
  #         - build: 'metal'
  #           defines: '-DLLAMA_NATIVE=OFF -DLLAMA_FAST=ON -DLLAMA_BUILD_SERVER=ON -DBUILD_SHARED_LIBS=ON'

  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v2
  #       with:
  #         repository: ggerganov/llama.cpp

  #     - name: Compile with cmake.
  #       run: |
  #         mkdir build
  #         cd build
  #         cmake .. ${{ matrix.defines }}
  #         cmake --build . --config Release

  #     - name: Pack Artifacts
  #       run: |
  #         cd build/bin
  #         ls Release
  # windows-cpu-only:
  #   runs-on: windows-latest

  #   strategy:
  #     matrix:
  #       include:
  #         - build: 'noavx'
  #           defines: '-DLLAMA_NATIVE=OFF -DLLAMA_FAST=ON -DLLAMA_BUILD_SERVER=ON -DLLAMA_AVX=OFF -DLLAMA_AVX2=OFF -DLLAMA_FMA=OFF -DBUILD_SHARED_LIBS=ON'
  #         - build: 'avx2'
  #           defines: '-DLLAMA_NATIVE=OFF -DLLAMA_FAST=ON -DLLAMA_BUILD_SERVER=ON -DBUILD_SHARED_LIBS=ON'
  #         - build: 'avx'
  #           defines: '-DLLAMA_NATIVE=OFF -DLLAMA_FAST=ON -DLLAMA_BUILD_SERVER=ON -DLLAMA_AVX2=OFF -DBUILD_SHARED_LIBS=ON'
  #         - build: 'avx512'
  #           defines: '-DLLAMA_NATIVE=OFF -DLLAMA_FAST=ON -DLLAMA_BUILD_SERVER=ON -DLLAMA_AVX512=ON -DBUILD_SHARED_LIBS=ON'
  
  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v2
  #       with:
  #         repository: ggerganov/llama.cpp

  #     - name: Compile with cmake.
  #       run: |
  #         mkdir build
  #         cd build
  #         cmake .. ${{ matrix.defines }}
  #         cmake --build . --config Release

  #     - name: Pack Artifacts
  #       run: |
  #         cd build/bin
  #         ls Release

  # windows-cuda:
  #   runs-on: windows-latest

  #   strategy:
  #     matrix:
  #       include:
  #         - build: 'cublas'
  #           defines: '-DLLAMA_NATIVE=OFF -DLLAMA_FAST=ON -DLLAMA_BUILD_SERVER=ON -DLLAMA_CUBLAS=ON -DBUILD_SHARED_LIBS=ON'

  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v2
  #       with:
  #         repository: ggerganov/llama.cpp

  #     - name: Install CUDA
  #       uses: Jimver/cuda-toolkit@v0.2.11
  #       id: cuda-toolkit
  #       with:
  #         cuda: '12.2.0'
  #         method: 'network'
  #         sub-packages: '["nvcc", "cudart", "cublas", "cublas_dev", "thrust", "visual_studio_integration"]'

  #     - name: Compile with cmake.
  #       run: |
  #         mkdir build
  #         cd build
  #         cmake .. ${{ matrix.defines }}
  #         cmake --build . --config Release

  #     - name: Pack Artifacts
  #       run: |
  #         cd build/bin
  #         ls Release